<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<!--
Design by Free CSS Templates
http://www.freecsstemplates.org
Released for free under a Creative Commons Attribution 2.5 License

Name       : SquareAway 
Description: A four-column, fixed-width design with dark color scheme.
Version    : 1.0
Released   : 20130804

-->
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>SquareAway</title>
<meta name="keywords" content="" />
<meta name="description" content="" />
<link href="http://fonts.googleapis.com/css?family=Source+Sans+Pro:200,300,400,600,700,900|Open+Sans:400,300,600,700,800" rel="stylesheet" />
<link href="default.css" rel="stylesheet" type="text/css" media="all" />
<link href="fonts.css" rel="stylesheet" type="text/css" media="all" />

<!--[if IE 6]><link href="default_ie6.css" rel="stylesheet" type="text/css" /><![endif]-->

</head>
<body>
<div id="logo" class="container">
	<h1><a href="#" class="icon icon-spinner"><span>big data? small yellow duck</span></a></h1>
</div>
<div id="header">
	<div id="menu" class="container">
		<ul>
			<li class="current_page_item"><a href="index.html" accesskey="1" title="">Homepage</a></li>
			<li><a href="about.html" accesskey="1" title="">About</a></li>

		</ul>
	</div>
</div>


<div id="page-wrapper">
	<div id="banner" class="container"><a href="#"><img src="images/skyline.jpg" width="1200"  alt="" /></a></div>

	
	<div id="featured" class="container">
		<div class="box">
			<div class="title">
				<h2>Predicting loan defaults</h2>
			</div>
			<p>
			<hr width=900 align=left>
			<table><tr width=900>
			<a href='https://www.kaggle.com/c/loan-default-prediction'>Loan Default Prediction</a> was a Kaggle 
			competition to predict if a loan will default and how much of the loan will be lost in the case of a default.
			My code is <a href='https://github.com/small-yellow-duck/loan_default'>here</a>.
			</tr></table>
			
			<hr width=900 align=left>
			
			<p>

			<table><tr width=900>
			<td width = 900 valign=top>
			<font style="line-height:2.0"> 
			<p>The data set consists of 700-odd <i>anonymized</i> features - so even if I did know something about
			evaluating loan risk, I wouldn't be able to put my intuition to use to recombine features in
			instructive ways. Time to learn more about machine learning!
			
			<p>Some of the data consisted of very large numbers, which python imported as objects instead of 
			integers. I coped with this by writing a "convert" function which returned the object data as ints or floats. <a href='https://github.com/small-yellow-duck/loan_default'>[code]</a>
			
			<p>Not much happened in the competition for a few weeks because just predicting
			which loans would default was a hard problem. I initially tried to reduce the data using PCA or by eliminating
			features which were highly correlated. But even with the reduced data, none of the tools in sklearn did any better than just guessing
			"no default" for every loan. 
			
			<p>Yasser Tabandeh <a href='https://www.kaggle.com/c/loan-default-prediction/forums/t/7115/golden-features'>eventually pointed out<a>  that
			using the binomial model from the glm packages in statsmodels with two particular features was a good
			predictor of defaults. 
			
			<p>But why did sklearn fail while glm succeeded? One reason is that values of a feature in the test data were often much 
			larger than values of the same feature in the training data. dolaameng pointed out that
			<a href='https://www.kaggle.com/c/loan-default-prediction/forums/t/6982/beating-the-benchmark?page=3'> "the local neighbor models are good at interpolation but very bad at extrapolation."</a>
			</tr></table>
		</div>
	</div>			


	<div id="featured" class="container">
		<div class="box">	
			<div class="title">
				<h2>Classifying default / non-default</h2>
			</div>					
			<table><tr width=900>			
			<td width=900 valign=top><font style="line-height:2.0"> 
			Like many other Kagglers, my strategy was first to classify loans as either "default" or "non-default"
			and then apply a regression tool to predict the score for those loans that defaulted. 

			<p><p>Using the binomial generalized linear model in the statsmodels.glm package to classify the
			loans as "default" or "non-default" is suggested by the substantial differences between the 
			values of features in the test data and in the training data. Logistic regression might also work well.
			</td>
			</tr>
			</table>
			
			<table>
			<tr>
			<td  valign=top width=350> <font style="line-height:2.0"> 
			<b><ul>Identifying useful features</ul></b> 
			Since no one single feature is especially predictive of whether a loan defaults or not
			and since there are several features which differ only slightly, it makes sense to examine
			pairs of features to see if the two features together are valuable. Two nested loops to
			investigate all these combinations was time-consuming (an overnight operation), but 
			allowed me to identify the "golden features". 
			
			<p><p>Since the binomial glm classifier returns a value between 0 and 1, I used the <a href='https://www.kaggle.com/wiki/AreaUnderCurve'>area-under-the-curve</a>
			to quantify the quality of the prediction. An AUC of 0.5 corresponds to random guessing, while an AUC of 1
			corresponds to classifying every loan correctly. I also needed to select a cutoff value for labeling 
			the loans as "default" or "not-default". I chose 0.66 because it produced the best results
			in the subsequent step: using regression to predict loss for defaults.
			
			</td>
			<td valign=top width = 550>
			<img src="/loan_default/auc_zoom.png" width = 550>
			</td>
			</tr>
			</table>
			
			
		</div>
	</div>
	
	<div id="featured" class="container">
		<div class="box">	
			<div class="title">
				<h2>Using regression to predict loss for defaulted loans</h2>
			</div>	
			
			<table><tr width=460>
<!-- 
			<td valign=top align=left width=450>
			<figure>
			<img src="titanic/Title_Class_Family Size.png" width=450 >
			<figcaption width=450>Fig 1: Predicting survival using title, class and family size</figcaption></figure>
			</td>
 -->			
			<td width = 440 valign=top>
			<font style="line-height:2.0">
			After training the statsmodels classifier to predict defaults with some success, I used sklearn's
			RandomForestRegressor to generate predictions of the loss.
			
			<p><p>My most useful insight here was to train the classifier on my training subset, then apply the
			classifier to the training subset and use all the loans that my classifier identified as "default" to train my regressor. 
			This meant that I included loans that the classifier had incorrectly labelled as "default" when I 
			trained the regressor. 
			
			<p><p>RandomForestRegressor seemed to do the best job at estimating the loss. It turned out to be
			very profitable to <b>include the output from the glm classifier as an additional input
			to RandomForestRegressor</b>. I was able to decrease my competition score (MAE) by about 0.1 this way.
			
			</td>
			</tr>


			

			
			</table>
			
			
	
				
		</div>
		
	</div>



</div>



<div id="copyright">
	<p>Copyright (c) 2013 small yellow duck. All rights reserved. Design by <a href="http://www.freecsstemplates.org/" rel="nofollow">FreeCSSTemplates.org</a>.</p>
</div>
</body>
</html>